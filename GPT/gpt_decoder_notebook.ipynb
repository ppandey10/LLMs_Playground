{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Start by importing necessary libraries\n",
    "import numpy as np\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check for cuda\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Setting important hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-4\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_heads = 4\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Looking at the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270153\n"
     ]
    }
   ],
   "source": [
    "with open('/Net/Groups/BGI/scratch/ppandey/LLMs_Playground/The_Great_Gatsby.txt', 'r', encoding='utf-8') as file:\n",
    "    txt_file = file.read()\n",
    "print(len(txt_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Construct a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ç', 'é', 'ê', 'ô', '\\u200a', '—', '‘', '’', '“', '”', '…', '\\ufeff']\n",
      "Total number of unique characters/Vocabulary size: 88\n"
     ]
    }
   ],
   "source": [
    "# Get unique characters\n",
    "chars = sorted(set(txt_file))\n",
    "print(chars)\n",
    "vocabulary_size = len(chars)\n",
    "print('Total number of unique characters/Vocabulary size:', vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '\\n'), (1, ' '), (2, '!'), (3, '$'), (4, '('), (5, ')'), (6, '*'), (7, ','), (8, '-'), (9, '.'), (10, '0'), (11, '1'), (12, '2'), (13, '3'), (14, '4'), (15, '5'), (16, '6'), (17, '7'), (18, '8'), (19, '9'), (20, ':'), (21, ';'), (22, '?'), (23, 'A'), (24, 'B'), (25, 'C'), (26, 'D'), (27, 'E'), (28, 'F'), (29, 'G'), (30, 'H'), (31, 'I'), (32, 'J'), (33, 'K'), (34, 'L'), (35, 'M'), (36, 'N'), (37, 'O'), (38, 'P'), (39, 'Q'), (40, 'R'), (41, 'S'), (42, 'T'), (43, 'U'), (44, 'V'), (45, 'W'), (46, 'X'), (47, 'Y'), (48, '['), (49, ']'), (50, 'a'), (51, 'b'), (52, 'c'), (53, 'd'), (54, 'e'), (55, 'f'), (56, 'g'), (57, 'h'), (58, 'i'), (59, 'j'), (60, 'k'), (61, 'l'), (62, 'm'), (63, 'n'), (64, 'o'), (65, 'p'), (66, 'q'), (67, 'r'), (68, 's'), (69, 't'), (70, 'u'), (71, 'v'), (72, 'w'), (73, 'x'), (74, 'y'), (75, 'z'), (76, 'ç'), (77, 'é'), (78, 'ê'), (79, 'ô'), (80, '\\u200a'), (81, '—'), (82, '‘'), (83, '’'), (84, '“'), (85, '”'), (86, '…'), (87, '\\ufeff')]\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(chars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Characterwise tokensiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder and decoder for characterwise tokenisation\n",
    "string_to_int = {\n",
    "    ch:i for i,ch in enumerate(chars)\n",
    "}\n",
    "\n",
    "int_to_string = {\n",
    "    i:ch for i,ch in enumerate(chars)\n",
    "}\n",
    "\n",
    "charwise_encoder = lambda input_word: [string_to_int[char] for char in input_word]\n",
    "charwise_decoder = lambda input_tokenised_word: ''.join([int_to_string[i] for i in input_tokenised_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 50, 56, 59, 58, 69, 1, 41, 58, 63, 56, 57]\n"
     ]
    }
   ],
   "source": [
    "# Experimenting with tokeniser\n",
    "encoded_Jagjit_Singh = charwise_encoder('Jagjit Singh')\n",
    "print(encoded_Jagjit_Singh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jagjit Singh\n"
     ]
    }
   ],
   "source": [
    "decoded_Jagjit_Singh = charwise_decoder(encoded_Jagjit_Singh)\n",
    "print(decoded_Jagjit_Singh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63, 54, 67, 50, 51, 61, 54,  1, 74,\n",
      "        54, 50, 67, 68,  1, 62, 74,  1, 55, 50, 69, 57, 54, 67])\n"
     ]
    }
   ],
   "source": [
    "# Convert the txt_file from array/list to tensor\n",
    "data = torch.tensor(charwise_encoder(txt_file), dtype=torch.long)\n",
    "print(data[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_percentage_split = int(0.9*len(data))\n",
    "train_data = data[:train_percentage_split] # 90% training \n",
    "val_data = data[train_percentage_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: tensor([87]) ; target: tensor(31)\n",
      "context: tensor([87, 31]) ; target: tensor(63)\n",
      "context: tensor([87, 31, 63]) ; target: tensor(1)\n",
      "context: tensor([87, 31, 63,  1]) ; target: tensor(62)\n",
      "context: tensor([87, 31, 63,  1, 62]) ; target: tensor(74)\n",
      "context: tensor([87, 31, 63,  1, 62, 74]) ; target: tensor(1)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1]) ; target: tensor(74)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74]) ; target: tensor(64)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64]) ; target: tensor(70)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70]) ; target: tensor(63)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63]) ; target: tensor(56)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56]) ; target: tensor(54)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54]) ; target: tensor(67)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67]) ; target: tensor(1)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1]) ; target: tensor(50)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50]) ; target: tensor(63)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63]) ; target: tensor(53)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53]) ; target: tensor(1)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1]) ; target: tensor(62)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62]) ; target: tensor(64)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64]) ; target: tensor(67)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67]) ; target: tensor(54)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54]) ; target: tensor(1)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1]) ; target: tensor(71)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71]) ; target: tensor(70)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70]) ; target: tensor(61)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61]) ; target: tensor(63)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63]) ; target: tensor(54)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63, 54]) ; target: tensor(67)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63, 54, 67]) ; target: tensor(50)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63, 54, 67, 50]) ; target: tensor(51)\n",
      "context: tensor([87, 31, 63,  1, 62, 74,  1, 74, 64, 70, 63, 56, 54, 67,  1, 50, 63, 53,\n",
      "         1, 62, 64, 67, 54,  1, 71, 70, 61, 63, 54, 67, 50, 51]) ; target: tensor(61)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    targ = y[i]\n",
    "    print('context:', context, ';', 'target:', targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create `get_batch` function. Kind of dataloader\n",
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    random_indexes = torch.randint(0, (len(data) - block_size), (batch_size,))\n",
    "    # print(random_indexes)\n",
    "    x = torch.stack([data[i:i+block_size] for i in random_indexes])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in random_indexes])\n",
    "    # move the data to gpus\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context/inputs:\n",
      "tensor([[62, 68, 54, 61, 55,  1, 58, 63, 69, 64,  1, 50,  1, 68, 57, 50, 53, 64,\n",
      "         72,  1, 50, 63, 53,  7,  0, 72, 57, 58, 61, 54,  1, 26],\n",
      "        [70, 67,  1, 64, 55,  1, 69, 57, 54,  1, 72, 50, 61, 61, 68,  9,  1, 23,\n",
      "          0, 72, 57, 58, 69, 54,  1, 50, 68, 57, 54, 63,  1, 53],\n",
      "        [74,  1, 57, 64, 70, 68, 54,  1, 61, 64, 64, 60, 68,  1, 72, 54, 61, 61,\n",
      "          7,  1, 53, 64, 54, 68, 63, 83, 69,  1, 58, 69, 22, 85],\n",
      "        [58, 63, 56,  1, 69, 64,  1, 69, 57, 54,  1, 40, 54, 53,  0, 25, 67, 64,\n",
      "         68, 68,  1, 69, 64,  1, 62, 50, 60, 54,  1, 51, 50, 63],\n",
      "        [53,  7,  1, 84, 27, 73, 52, 70, 68, 54,  0, 62, 54, 85, 81, 51, 70, 69,\n",
      "          1, 69, 57, 58, 68,  1, 69, 58, 62, 54,  1, 63, 64,  1],\n",
      "        [ 9,  1, 30, 54, 67,  1, 54, 74, 54, 68,  1, 55, 54, 61, 61,  1, 64, 63,\n",
      "          1, 32, 64, 67, 53, 50, 63,  1, 50, 63, 53,  1, 62, 54],\n",
      "        [57, 50, 69,  1, 52, 64, 67, 67, 54, 52, 69, 54, 53,  1, 51, 67, 64, 72,\n",
      "          1, 64, 55,  1, 57, 54, 67, 68,  7,  1, 50, 63, 53,  1],\n",
      "        [65, 69, 58, 51, 61, 54,  1, 67, 54, 61, 70, 52, 69, 50, 63, 52, 54,  9,\n",
      "          0,  0, 84, 36, 64, 69,  1, 50, 69,  1, 33, 50, 65, 58],\n",
      "        [67, 61,  7,  1, 26, 50, 58, 68, 74,  7,  1, 62, 50, 53, 54,  1, 50, 63,\n",
      "          1, 50, 69, 69, 54, 62, 65, 69,  1, 69, 64,  1, 67, 58],\n",
      "        [67, 53,  1, 57, 58, 62, 68, 54, 61, 55,  1, 68, 50, 74,  1, 69, 57, 58,\n",
      "         68,  7,  1, 57, 54,  1, 55, 61, 58, 63, 52, 57, 54, 53],\n",
      "        [58, 69, 64, 67, 58, 50, 61, 68,  1, 55, 64, 67,  1, 69, 57, 54,  1, 47,\n",
      "         50, 61, 54,  1, 36, 54, 72, 68, 81, 50, 63, 53,  1, 63],\n",
      "        [84, 47, 64, 70,  1, 50, 61, 72, 50, 74, 68,  1, 61, 64, 64, 60,  1, 68,\n",
      "         64,  1, 52, 64, 64, 61,  7, 85,  1, 68, 57, 54,  1, 67],\n",
      "        [ 1, 57, 50, 53,  1, 64, 70, 69, 61, 58, 63, 54, 53,  1, 58, 63,  1, 69,\n",
      "         57, 54,  1, 56, 50, 67, 53, 54, 63,  9,  0,  0, 42, 57],\n",
      "        [67,  1, 57, 54,  1, 60, 63, 54, 72,  9,  1, 42, 57, 64, 70, 56, 57,  1,\n",
      "         31,  1, 72, 50, 68,  1, 52, 70, 67, 58, 64, 70, 68,  1],\n",
      "        [67, 58, 54, 53,  1, 26, 50, 58, 68, 74,  1, 72, 58, 69, 57,  1, 69, 54,\n",
      "         63, 68, 54,  1, 56, 50, 58, 54, 69, 74,  9,  0,  0, 41],\n",
      "        [ 1, 69, 57, 54,  1, 62, 64, 71, 58, 54, 68,  9,  0,  0, 84, 41, 57, 54,\n",
      "         83, 68,  1, 61, 64, 71, 54, 61, 74,  7, 85,  1, 68, 50]],\n",
      "       device='cuda:0')\n",
      "target:\n",
      "tensor([[68, 54, 61, 55,  1, 58, 63, 69, 64,  1, 50,  1, 68, 57, 50, 53, 64, 72,\n",
      "          1, 50, 63, 53,  7,  0, 72, 57, 58, 61, 54,  1, 26, 50],\n",
      "        [67,  1, 64, 55,  1, 69, 57, 54,  1, 72, 50, 61, 61, 68,  9,  1, 23,  0,\n",
      "         72, 57, 58, 69, 54,  1, 50, 68, 57, 54, 63,  1, 53, 70],\n",
      "        [ 1, 57, 64, 70, 68, 54,  1, 61, 64, 64, 60, 68,  1, 72, 54, 61, 61,  7,\n",
      "          1, 53, 64, 54, 68, 63, 83, 69,  1, 58, 69, 22, 85,  1],\n",
      "        [63, 56,  1, 69, 64,  1, 69, 57, 54,  1, 40, 54, 53,  0, 25, 67, 64, 68,\n",
      "         68,  1, 69, 64,  1, 62, 50, 60, 54,  1, 51, 50, 63, 53],\n",
      "        [ 7,  1, 84, 27, 73, 52, 70, 68, 54,  0, 62, 54, 85, 81, 51, 70, 69,  1,\n",
      "         69, 57, 58, 68,  1, 69, 58, 62, 54,  1, 63, 64,  1, 64],\n",
      "        [ 1, 30, 54, 67,  1, 54, 74, 54, 68,  1, 55, 54, 61, 61,  1, 64, 63,  1,\n",
      "         32, 64, 67, 53, 50, 63,  1, 50, 63, 53,  1, 62, 54,  1],\n",
      "        [50, 69,  1, 52, 64, 67, 67, 54, 52, 69, 54, 53,  1, 51, 67, 64, 72,  1,\n",
      "         64, 55,  1, 57, 54, 67, 68,  7,  1, 50, 63, 53,  1, 68],\n",
      "        [69, 58, 51, 61, 54,  1, 67, 54, 61, 70, 52, 69, 50, 63, 52, 54,  9,  0,\n",
      "          0, 84, 36, 64, 69,  1, 50, 69,  1, 33, 50, 65, 58, 64],\n",
      "        [61,  7,  1, 26, 50, 58, 68, 74,  7,  1, 62, 50, 53, 54,  1, 50, 63,  1,\n",
      "         50, 69, 69, 54, 62, 65, 69,  1, 69, 64,  1, 67, 58, 68],\n",
      "        [53,  1, 57, 58, 62, 68, 54, 61, 55,  1, 68, 50, 74,  1, 69, 57, 58, 68,\n",
      "          7,  1, 57, 54,  1, 55, 61, 58, 63, 52, 57, 54, 53,  1],\n",
      "        [69, 64, 67, 58, 50, 61, 68,  1, 55, 64, 67,  1, 69, 57, 54,  1, 47, 50,\n",
      "         61, 54,  1, 36, 54, 72, 68, 81, 50, 63, 53,  1, 63, 64],\n",
      "        [47, 64, 70,  1, 50, 61, 72, 50, 74, 68,  1, 61, 64, 64, 60,  1, 68, 64,\n",
      "          1, 52, 64, 64, 61,  7, 85,  1, 68, 57, 54,  1, 67, 54],\n",
      "        [57, 50, 53,  1, 64, 70, 69, 61, 58, 63, 54, 53,  1, 58, 63,  1, 69, 57,\n",
      "         54,  1, 56, 50, 67, 53, 54, 63,  9,  0,  0, 42, 57, 54],\n",
      "        [ 1, 57, 54,  1, 60, 63, 54, 72,  9,  1, 42, 57, 64, 70, 56, 57,  1, 31,\n",
      "          1, 72, 50, 68,  1, 52, 70, 67, 58, 64, 70, 68,  1, 69],\n",
      "        [58, 54, 53,  1, 26, 50, 58, 68, 74,  1, 72, 58, 69, 57,  1, 69, 54, 63,\n",
      "         68, 54,  1, 56, 50, 58, 54, 69, 74,  9,  0,  0, 41, 57],\n",
      "        [69, 57, 54,  1, 62, 64, 71, 58, 54, 68,  9,  0,  0, 84, 41, 57, 54, 83,\n",
      "         68,  1, 61, 64, 71, 54, 61, 74,  7, 85,  1, 68, 50, 58]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Working with get_batch function\n",
    "x, y = get_batch('train')\n",
    "print('context/inputs:')\n",
    "print(x)\n",
    "print('target:')\n",
    "print(y)\n",
    "\n",
    "# We will have 4 random int values which is the starting point of each batch and have corresponding target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Creating the Bigram class\n",
    "\n",
    "Just for the context on what does `nn.Embedding` give as an output:\n",
    "\n",
    "```python\n",
    "vocab_size = 4000\n",
    "embedding_dim = 5 \n",
    "# In a sense, this is 5 dimensional space where each element of vocab is represented by a vector in that space.\n",
    "\n",
    "# Initialise the embedding layer\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Create some example input data\n",
    "input_data = torch.LongTensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "# Pass the input data through the embedding layer\n",
    "embedded_data = embedding(input_data)\n",
    "\n",
    "print(embedded_data.shape)\n",
    "# 2 is the batch size, 4 is the sequence length, and 5 is the embedding dimension\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval() # good practice: keep in mind the mode we are in. this helps us understand/build our model correctly. \n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, I want my model to informed about the past information. Taking the weighted sum of the past. (Not the most efficient way but it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.4649e-01, 4.5351e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [5.6845e-01, 6.0980e-02, 3.7056e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.6899e-02, 1.4698e-01, 4.3027e-01, 4.0585e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.7021e-01, 6.0117e-02, 3.2039e-01, 4.4503e-02, 3.0478e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [2.2065e-02, 7.7512e-01, 2.7749e-02, 8.8687e-04, 1.3792e-01, 3.6263e-02,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.4623e-02, 3.7534e-01, 3.0217e-02, 7.4997e-03, 2.9236e-02, 2.6814e-01,\n",
      "         2.7495e-01, 0.0000e+00],\n",
      "        [1.0809e-01, 1.9375e-01, 6.8777e-02, 2.8949e-02, 2.2153e-02, 2.7387e-01,\n",
      "         2.4071e-01, 6.3709e-02]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Maths behind self-attention: \n",
    "B, T, C = 4, 8, 32\n",
    "random_tensor = torch.randn((B, T, C))\n",
    "\n",
    "# Create a single head attention \n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(random_tensor) # (B, T, 16)\n",
    "q = query(random_tensor) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) * (B, 16, T) --> (B, T, T)\n",
    "\n",
    "# Now, we have to mix the information i.e past and present which will fed into our model.\n",
    "# As discussed, to combine the informations we use weighted sum approach. Clever use of matrix multiplication and softmax for normalisation\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T)) # generally, this shouldnt be uniform. therefore, implemented key-query approach\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) # sum of each row will be equal to 1\n",
    "\n",
    "v = value(random_tensor)\n",
    "out = wei @ v # This is something which is aggregated\n",
    "x_bag_of_words = wei @ random_tensor # x or random_tensor is something which private in context of a particular token\n",
    "# print(x_bag_of_words.shape)\n",
    "print(wei[0]) # looking at single batch \n",
    "# Since we will have different tokens in different position for each batch. therefore, we will have different weight distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main idea behind Self-Attention: Gather information from the past in a data dependent way!\n",
    "\n",
    "How does it solve this?\n",
    "Every single token at each position emits two vectors:\n",
    "- Query: What am I looking for?\n",
    "- Key: What do I contain!\n",
    "\n",
    "We do the dot product of query with each of the key which ultimately is my `wei`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Head class \n",
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        # during training head, query and value are changes\n",
    "\n",
    "        # tril is not a parameter for our model so we create a buffer\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        # add droupout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        # calculate attention score/wei\n",
    "        wei = q @ k.transpose(-2,-1) * C**(-0.5)\n",
    "        # masking the wei \n",
    "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
    "        # apply softmax\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # dropout layers\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of value\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''multiple heads of self attention in parallel'''\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        # introduce the residual connection\n",
    "        # project the output of heads\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        # apply dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # concatenate the result of each head\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    '''a simple feed-forward block'''\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4*n_embd), # increased the output channel \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embd, n_embd), # back to same number of channels\n",
    "            # add dropout for stable model\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Transformer Block'''\n",
    "    \n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_heads\n",
    "        self.sa = MultiHeadAttention(n_heads, head_size) # Head(n_embd) where, head_size = n_embd\n",
    "        self.ffwd = FeedForwardBlock(n_embd)\n",
    "        self.lay_norm_1 = nn.LayerNorm(n_embd)\n",
    "        self.lay_norm_2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.lay_norm_1(x))\n",
    "        x = x + self.ffwd(self.lay_norm_2(x))\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self): # remove the vocab_size\n",
    "        super().__init__()\n",
    "\n",
    "        # creating a readoff table. Size: vocab_size x vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        # introduce head in the constructor\n",
    "        # replace the sa_head with multiple attention \n",
    "        # self.sa_heads = MultiHeadAttention(4, n_embd//4) # Head(n_embd) where, head_size = n_embd\n",
    "        # since, we are concatenating the results individual SA block should have n_emdb // 4 channels so that on concatenation, we have n_embd = 32]\n",
    "        # self.ff = FeedForwardBlock(n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd, n_heads=4),\n",
    "            Block(n_embd, n_heads=4),\n",
    "            Block(n_embd, n_heads=4),\n",
    "            nn.LayerNorm(n_embd),\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_embd, vocabulary_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(index) # (batch, seq length/time, channels); (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(0, T, device=device)) # (T, C)\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.blocks(x) # self.sa_head(x) --> self.sa_heads(x) --> self.blocks(x)\n",
    "        # x = self.ff(x)# (per node level) which helps the token to think about what they found \n",
    "        logits = self.lm_head(x) # (batch, time, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # read cross_entropy documentation to get the idea about the inputs\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # stretches out the matrix along single dimension\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets) # log-likelihood = -ln(probability)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:] # modified this since idx going in my can not exceed th block size\n",
    "            # get predictions\n",
    "            logits, loss = self.forward(idx_cond) # or self(index)\n",
    "            # focus only on last time step\n",
    "            logits = logits[:, -1, :] # (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probabs = F.softmax(logits, dim=-1)\n",
    "            # getting the probability\n",
    "            index_next = torch.multinomial(probabs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, index_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does `view` work?\n",
    "\n",
    "```python \n",
    "a:\n",
    "tensor([[[5, 0, 9],\n",
    "         [5, 9, 8],\n",
    "         [5, 3, 1]],\n",
    "\n",
    "        [[1, 4, 4],\n",
    "         [3, 0, 8],\n",
    "         [3, 8, 9]]])\n",
    "a_after_view:\n",
    "tensor([[5, 0, 9],\n",
    "        [5, 9, 8],\n",
    "        [5, 3, 1],\n",
    "        [1, 4, 4],\n",
    "        [3, 0, 8],\n",
    "        [3, 8, 9]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logits Explained\n",
    "\n",
    "1. After processing input data through the layers of a neural network, the final layer generates a set of raw scores or values for each class in a classification task. These raw scores are often referred to as logits.\n",
    "\n",
    "2. **Purpose:** Logits provide a measure of confidence or certainty that the model assigns to each class. Higher logits indicate greater confidence in a particular class, while lower logits indicate less confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   0%|          | 1/10000 [00:02<7:05:22,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.673, val loss: 4.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   2%|▏         | 205/10000 [00:07<15:55, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200, train loss: 3.206, val loss: 3.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   4%|▍         | 409/10000 [00:13<11:44, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 400, train loss: 2.912, val loss: 2.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   6%|▌         | 607/10000 [00:18<11:30, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 600, train loss: 2.755, val loss: 2.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::   8%|▊         | 805/10000 [00:23<14:50, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 800, train loss: 2.677, val loss: 2.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  10%|█         | 1009/10000 [00:29<11:00, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000, train loss: 2.612, val loss: 2.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  12%|█▏        | 1207/10000 [00:34<10:46, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1200, train loss: 2.575, val loss: 2.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  14%|█▍        | 1405/10000 [00:39<13:50, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1400, train loss: 2.541, val loss: 2.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  16%|█▌        | 1609/10000 [00:45<10:18, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1600, train loss: 2.534, val loss: 2.550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  18%|█▊        | 1807/10000 [00:50<10:02, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1800, train loss: 2.502, val loss: 2.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  20%|██        | 2005/10000 [00:55<12:55, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2000, train loss: 2.493, val loss: 2.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  22%|██▏       | 2209/10000 [01:00<09:32, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2200, train loss: 2.474, val loss: 2.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  24%|██▍       | 2407/10000 [01:06<09:16, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2400, train loss: 2.454, val loss: 2.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  26%|██▌       | 2605/10000 [01:11<11:57, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2600, train loss: 2.438, val loss: 2.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  28%|██▊       | 2809/10000 [01:16<08:47, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2800, train loss: 2.432, val loss: 2.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  30%|███       | 3007/10000 [01:22<08:33, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3000, train loss: 2.421, val loss: 2.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  32%|███▏      | 3205/10000 [01:27<10:56, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3200, train loss: 2.402, val loss: 2.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  34%|███▍      | 3409/10000 [01:32<08:02, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3400, train loss: 2.394, val loss: 2.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  36%|███▌      | 3607/10000 [01:37<07:47, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3600, train loss: 2.380, val loss: 2.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  38%|███▊      | 3805/10000 [01:43<10:00, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3800, train loss: 2.374, val loss: 2.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  40%|████      | 4009/10000 [01:48<07:20, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4000, train loss: 2.360, val loss: 2.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  42%|████▏     | 4207/10000 [01:53<07:05, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4200, train loss: 2.347, val loss: 2.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  44%|████▍     | 4405/10000 [01:58<09:03, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4400, train loss: 2.331, val loss: 2.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  46%|████▌     | 4609/10000 [02:04<06:36, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4600, train loss: 2.325, val loss: 2.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  48%|████▊     | 4807/10000 [02:09<06:22, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4800, train loss: 2.329, val loss: 2.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  50%|█████     | 5005/10000 [02:14<08:04, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5000, train loss: 2.310, val loss: 2.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  52%|█████▏    | 5209/10000 [02:20<05:52, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5200, train loss: 2.297, val loss: 2.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  54%|█████▍    | 5407/10000 [02:25<05:37, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5400, train loss: 2.287, val loss: 2.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  56%|█████▌    | 5605/10000 [02:30<07:05, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5600, train loss: 2.278, val loss: 2.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  58%|█████▊    | 5809/10000 [02:36<05:07, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5800, train loss: 2.268, val loss: 2.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  60%|██████    | 6007/10000 [02:41<04:54, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6000, train loss: 2.255, val loss: 2.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  62%|██████▏   | 6205/10000 [02:46<06:08, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6200, train loss: 2.253, val loss: 2.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  64%|██████▍   | 6409/10000 [02:51<04:23, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6400, train loss: 2.238, val loss: 2.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  66%|██████▌   | 6607/10000 [02:57<04:09, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6600, train loss: 2.228, val loss: 2.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  68%|██████▊   | 6805/10000 [03:02<05:09, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6800, train loss: 2.220, val loss: 2.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  70%|███████   | 7009/10000 [03:07<03:39, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7000, train loss: 2.208, val loss: 2.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  72%|███████▏  | 7207/10000 [03:13<03:25, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7200, train loss: 2.203, val loss: 2.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  74%|███████▍  | 7405/10000 [03:18<04:11, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7400, train loss: 2.202, val loss: 2.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  76%|███████▌  | 7609/10000 [03:23<02:55, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7600, train loss: 2.191, val loss: 2.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  78%|███████▊  | 7807/10000 [03:28<02:40, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7800, train loss: 2.177, val loss: 2.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  80%|████████  | 8005/10000 [03:34<03:13, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8000, train loss: 2.167, val loss: 2.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  82%|████████▏ | 8209/10000 [03:39<02:11, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8200, train loss: 2.169, val loss: 2.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  84%|████████▍ | 8407/10000 [03:44<01:57, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8400, train loss: 2.165, val loss: 2.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  86%|████████▌ | 8605/10000 [03:50<02:15, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8600, train loss: 2.155, val loss: 2.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  88%|████████▊ | 8809/10000 [03:55<01:27, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8800, train loss: 2.150, val loss: 2.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  90%|█████████ | 9007/10000 [04:00<01:12, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9000, train loss: 2.133, val loss: 2.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  92%|█████████▏| 9205/10000 [04:05<01:16, 10.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9200, train loss: 2.145, val loss: 2.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  94%|█████████▍| 9409/10000 [04:11<00:43, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9400, train loss: 2.127, val loss: 2.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  96%|█████████▌| 9607/10000 [04:16<00:28, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9600, train loss: 2.119, val loss: 2.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss::  98%|█████████▊| 9805/10000 [04:21<00:18, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9800, train loss: 2.117, val loss: 2.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:: 100%|██████████| 10000/10000 [04:25<00:00, 37.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = GPTModel() # vocabulary_size=88 (The_Great_Gatsby)\n",
    "m = model.to(device)\n",
    "\n",
    "# start by defining an optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_progress = []\n",
    "\n",
    "for i in tqdm(range(max_iters), desc=\"loss:\"):\n",
    "\n",
    "    if i % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {i}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data \n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # loss_progress.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dooud stidne. Le,\n",
      "croke—igh “Thin bech I wer imn aviges the messoped ben beaid an dichimest waorst ody he hon.\n",
      "\n",
      "Hiler fo he ears, lolly hood the jughitam frooved an’st up tht wione. I hooulf … thith thas suppemsse I dave ing loltixpdine of woled thee at cad thee\n",
      "ant—walen we es hearn tom jurte\n",
      "isy alathe kin piveroong ilom r weve\n",
      "uld, fave ! lettus dimyir arlol thet, whe\n",
      "was aby’m! horainy rit\n",
      "wat a hid thing\n",
      "cborick plinferomve. Docnie ‘y.\n",
      "\n",
      "“Whlode?”\n",
      "\n",
      "“I hime eackning affen uV then to thely up\n"
     ]
    }
   ],
   "source": [
    "# Lets do some predictions\n",
    "# Start by feeding some input (get some index)\n",
    "idx = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generate_values = m.generate(idx=idx, max_new_tokens=500)\n",
    "print(charwise_decoder(generate_values[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en23",
   "language": "python",
   "name": "kernel_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
