{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 0, 1, 1, 1, 2, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "probabilites = torch.tensor([0.1, 0.4, 0.5]) # they should always end up being equal to 1\n",
    "# there is 10% chance of getting 0, 40% chance of getting 1 and 50% chance of getting 2. \n",
    "# Meaning that we have probability of getting the corresponding index.\n",
    "samples = torch.multinomial(probabilites, num_samples=10, replacement=True)\n",
    "print(samples)\n",
    "\n",
    "# This concept will be used for getting the probabilities for next character prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "first_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "concatenated_tensor = torch.concatenate((first_tensor, torch.tensor([6, 7, 8, 9, 10])), axis=0)\n",
    "print(concatenated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "triangular_lower = torch.tril(torch.ones(8,8))\n",
    "print(triangular_lower)\n",
    "\n",
    "# This will be used for setting the predictions that we have made. \n",
    "# Meaning, we have the first token (already set to 1) but rest of them have to predicted so they are set as 0. \n",
    "# As we move forward, we make predictions and consequtively set them to 1. \n",
    "# This makes sure that we do not interact with the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Similar to the previous case, we have\n",
    "triangular_upper = torch.triu(torch.ones(8,8))\n",
    "print(triangular_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# So, this is one of the most important concepts for biagram model. We exponentiate our tensors.\n",
    "exp_triang_lower = torch.zeros(8,8).masked_fill(torch.tril(torch.ones(8,8))==0, float('-inf'))\n",
    "print(exp_triang_lower)\n",
    "\n",
    "# When we raise the tensor with exp. \n",
    "# e^{-inf} = 1; e^{0} = 1\n",
    "print(torch.exp(exp_triang_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Yet another simple function\n",
    "zeros_tensor = torch.zeros((5, 2, 3))\n",
    "transponsed_zeros_tensor = zeros_tensor.transpose(0, 2)\n",
    "print(transponsed_zeros_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Looking at quite an inportant function: `torch.stack`\n",
    "# We need this for parallel processing where we stack multiple blocks with fixed length (no. of tokens)\n",
    "tensor_1 = torch.tensor([1, 2, 3])\n",
    "tensor_2 = torch.tensor([4, 5, 6])\n",
    "tensor_3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "stacked_tensor = torch.stack((tensor_1, tensor_2, tensor_3))\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3292, -0.2261, -1.2684,  1.5387], grad_fn=<SqueezeBackward3>)\n",
      "tensor([0.0441, 0.1329, 0.0469, 0.7761], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Simple neural network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "input_tensor = torch.tensor([2., 3., 4]) # takes float\n",
    "linear_layer = nn.Linear(in_features=3, out_features=4, bias=False) # can change the output features but not the input\n",
    "output_tensor = linear_layer(input_tensor)\n",
    "print(output_tensor)\n",
    "\n",
    "# Lets try to store the output and then apply the activation function\n",
    "out_after_act = F.softmax(output_tensor, dim=0)\n",
    "print(out_after_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en23",
   "language": "python",
   "name": "kernel_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
