{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 0, 1, 1, 1, 2, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "probabilites = torch.tensor([0.1, 0.4, 0.5]) # they should always end up being equal to 1\n",
    "# there is 10% chance of getting 0, 40% chance of getting 1 and 50% chance of getting 2. \n",
    "# Meaning that we have probability of getting the corresponding index.\n",
    "samples = torch.multinomial(probabilites, num_samples=10, replacement=True)\n",
    "print(samples)\n",
    "\n",
    "# This concept will be used for getting the probabilities for next character prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "first_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "concatenated_tensor = torch.concatenate((first_tensor, torch.tensor([6, 7, 8, 9, 10])), axis=0)\n",
    "print(concatenated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "triangular_lower = torch.tril(torch.ones(8,8))\n",
    "print(triangular_lower)\n",
    "\n",
    "# This will be used for setting the predictions that we have made. \n",
    "# Meaning, we have the first token (already set to 1) but rest of them have to predicted so they are set as 0. \n",
    "# As we move forward, we make predictions and consequtively set them to 1. \n",
    "# This makes sure that we do not interact with the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Similar to the previous case, we have\n",
    "triangular_upper = torch.triu(torch.ones(8,8))\n",
    "print(triangular_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# So, this is one of the most important concepts for biagram model. We exponentiate our tensors.\n",
    "exp_triang_lower = torch.zeros(8,8).masked_fill(torch.tril(torch.ones(8,8))==0, float('-inf'))\n",
    "print(exp_triang_lower)\n",
    "\n",
    "# When we raise the tensor with exp. \n",
    "# e^{-inf} = 1; e^{0} = 1\n",
    "print(torch.exp(exp_triang_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Yet another simple function\n",
    "zeros_tensor = torch.zeros((5, 2, 3))\n",
    "transponsed_zeros_tensor = zeros_tensor.transpose(0, 2)\n",
    "print(transponsed_zeros_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Looking at quite an inportant function: `torch.stack`\n",
    "# We need this for parallel processing where we stack multiple blocks with fixed length (no. of tokens)\n",
    "tensor_1 = torch.tensor([1, 2, 3])\n",
    "tensor_2 = torch.tensor([4, 5, 6])\n",
    "tensor_3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "stacked_tensor = torch.stack((tensor_1, tensor_2, tensor_3))\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3292, -0.2261, -1.2684,  1.5387], grad_fn=<SqueezeBackward3>)\n",
      "tensor([0.0441, 0.1329, 0.0469, 0.7761], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Simple neural network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "input_tensor = torch.tensor([2., 3., 4]) # takes float\n",
    "linear_layer = nn.Linear(in_features=3, out_features=4, bias=False) # can change the output features but not the input\n",
    "output_tensor = linear_layer(input_tensor)\n",
    "print(output_tensor)\n",
    "\n",
    "# Lets try to store the output and then apply the activation function\n",
    "out_after_act = F.softmax(output_tensor, dim=0)\n",
    "print(out_after_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5])\n",
      "tensor([[[-0.4159, -0.0625,  0.8476, -0.1073, -1.0979],\n",
      "         [ 1.3862,  0.3097, -0.5616,  0.5898,  0.7091],\n",
      "         [ 0.2522,  0.9657,  0.3001,  2.0171,  0.0416],\n",
      "         [ 0.1790, -1.0683, -0.8860, -0.1840,  0.4192]],\n",
      "\n",
      "        [[-0.8543,  0.9594,  0.5434,  0.6422,  0.3213],\n",
      "         [ 1.7646,  1.2693,  0.0756, -2.1041,  1.0057],\n",
      "         [ 1.3222,  1.1394,  2.1730, -1.0531,  0.4475],\n",
      "         [-0.1500, -0.7864,  0.1142,  0.9328, -2.0393]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Using nn.Embedding\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 4000\n",
    "embedding_dim = 5 # In a sense, this is 5 dimensional space where each element of vocab is represented by a vector in that space.\n",
    "\n",
    "# Initialise the embedding layer\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Create some example input data\n",
    "input_data = torch.LongTensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "# Pass the input data through the embedding layer\n",
    "embedded_data = embedding(input_data)\n",
    "\n",
    "print(embedded_data.shape)\n",
    "print(embedded_data)\n",
    "# 2 is the batch size, 4 is the sequence length, and 5 is the embedding dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor multiplication\n",
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 8, 6],\n",
      "         [8, 5, 4],\n",
      "         [4, 8, 2]],\n",
      "\n",
      "        [[6, 0, 3],\n",
      "         [6, 8, 6],\n",
      "         [9, 7, 7]]])\n",
      "tensor([[4, 8, 2],\n",
      "        [9, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "matrix_a = torch.randint(low=0, high=10, size=(2, 3, 3))\n",
    "print(matrix_a)\n",
    "# B, T, C = matrix_a.shape\n",
    "# reshaped_matrix_a = matrix_a.view(B*T, C)\n",
    "print(matrix_a[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en23",
   "language": "python",
   "name": "kernel_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
